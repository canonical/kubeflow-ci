#!/usr/bin/python3
# Copyright 2024 Canonical Ltd.
# See LICENSE file for licensing details.
#

"""Script to process Trivy vulnerability scans reports and send those to Jira automation"""

import argparse
import json
import logging
import os
import sys
from pathlib import Path
from typing import Dict, List

import requests

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, stream=sys.stdout, format="%(message)s")

# https://support.atlassian.com/cloud-automation/docs/configure-the-incoming-webhook-trigger-in-atlassian-automation/
HEADER_JIRA_TOKEN = "X-Automation-Webhook-Token"

SEVERITY_CRITICAL = "CRITICAL"
SEVERITY_HIGH = "HIGH"
SEVERITY_MEDIUM = "MEDIUM"

PRIORITY_HIGHEST = "Highest"
PRIORITY_HIGH = "High"
PRIORITY_LOW = "Low"
PRIORITY_LOWEST = "Lowest"

LEVEL_HIGHEST = 3
LEVEL_HIGH = 2
LEVEL_LOW = 1
LEVEL_LOWEST = 0

severity_to_priority_map = {
    SEVERITY_CRITICAL: PRIORITY_HIGHEST,
    SEVERITY_HIGH: PRIORITY_HIGH,
    SEVERITY_MEDIUM: PRIORITY_LOW,
}

priority_to_level_map = {
    PRIORITY_HIGHEST: LEVEL_HIGHEST,
    PRIORITY_HIGH: LEVEL_HIGH,
    PRIORITY_LOW: LEVEL_LOW,
    PRIORITY_LOWEST: LEVEL_LOWEST,
}


def get_github_meta() -> Dict[str, str]:
    """Return a dictionary with GitHub metadata."""
    return {
        "github_server_url": os.getenv("GITHUB_SERVER_URL"),
        "github_run_id": os.getenv("GITHUB_RUN_ID"),
        "github_sha": os.getenv("GITHUB_SHA"),
        "github_repository": os.getenv("GITHUB_REPOSITORY"),
    }


def parse_json(filename: Path) -> List[Dict[str, str]]:
    """Parse JSON file.

    Args:
      filename(Path): path of file to parse.
    Returns:
      List[Dict[str, str]]: List of CVE dictionary.
    """

    record_list = []
    with open(filename, "r") as json_file:
        data = json.load(json_file)

    artifact = data["ArtifactName"]

    if "Results" not in data:
        # no scan results found, skip this report
        print(f"No results in report {filename}")
        return []

    for result in data["Results"]:
        if "Vulnerabilities" not in result or len(result["Vulnerabilities"]) == 0:
            # no vulnerabilities found, skip this report
            continue

        vuln_list = result["Vulnerabilities"]
        for vuln in vuln_list:
            artifact = artifact.replace(":", "-")
            artifact = artifact.replace("/", "-")
            record_name = f"{vuln['VulnerabilityID']}-{artifact}-{vuln['PkgName']}"
            record_list.append(
                {
                    "name": record_name,
                    "artifact": artifact,
                    "severity": vuln["Severity"],
                    "cve_id": vuln["VulnerabilityID"],
                    "package_name": vuln["PkgName"],
                    "installed_version": vuln["InstalledVersion"],
                    "fixed_version": vuln["FixedVersion"],
                    "title": vuln["Title"],
                    "description": vuln["Description"],
                    "references": "\n".join(vuln["References"]),
                    "primary_url": vuln["PrimaryURL"],
                    "priority": severity_to_priority_map.get(vuln["Severity"], PRIORITY_LOWEST),
                }
            )
    return record_list


def parse_sarif(filename: Path) -> List[Dict[str, str]]:
    """Parse SARIF file.

    Args:
      filename(Path): path of file to parse.
    Returns:
      List[Dict[str, str]]: List of CVE dictionary.
    """
    record_list = []
    with open(filename, "r") as json_file:
        data = json.load(json_file)
    if "runs" not in data and "tool" not in data["runs"][0]:
        # no scan results found, skip this report
        logger.warning(f"No results in report {filename}")
        return []

    rules = data["runs"][0]["tool"]["driver"]["rules"]
    results = data["runs"][0]["results"]

    for result in results:
        record_result = result
        record_rule = rules[result["ruleIndex"]]

        record_message = record_result["message"]["text"].split("\n")
        pkg_name = record_message[0].replace("Package: ", "")
        artifact = os.path.basename(filename).replace(".sarif", "")
        record_name = str(result["ruleId"] + "-" + artifact + "-" + pkg_name)
        severity = record_message[3].replace("Severity: ", "")
        record_list.append(
            {
                "name": record_name,
                "artifact": artifact,
                "severity": severity,
                "cve_id": result["ruleId"],
                "package_name": pkg_name,
                "installed_version": record_message[1].replace("Installed Version: ", ""),
                "fixed_version": record_message[4].replace("Fixed Version: ", ""),
                "title": record_rule["shortDescription"]["text"],
                "description": record_rule["help"]["text"],
                "references": "N/A",
                "primary_url": record_rule["helpUri"],
                "priority": severity_to_priority_map.get(severity, PRIORITY_LOWEST),
            }
        )
    return record_list


def filter_records(records: List[Dict[str, str]], min_level: int) -> List[Dict[str, str]]:
    """Filters the records based on the given minimum level.

    Args:
      records(List[Dict[str, str]]): List of CVE dictionaries.
      min_level(int): Minimum CVE level used for filtering the CVEs.
    Returns:
      List[Dict[str, str]]: List of CVE dictionaries which satisfy the criteria.
      List[Dict[str, str]]: List of CVE dictionaries which do not satisfy the criteria.
    """
    result = []
    excluded = []
    for record in records:
        level = priority_to_level_map[record["priority"]]
        if level >= min_level:
            result.append(record)
        else:
            excluded.append(record)

    return result, excluded


def send_request_with_records(
    records: List[Dict[str, str]],
    jira_url: str,
    jira_auth_token: str = "",
    gh_metadata: Dict[str, str] = {},
    verbose: bool = False,
) -> None:
    """Send the request with records to Jira.

    Args:
      records(List[Dict[str, str]]): a list of records of CVE's.
      jira_url(str): the url to send the request to.
      jira_auth_token(str): the auth token to use when sending requests to Jira.
        https://support.atlassian.com/cloud-automation/docs/configure-the-incoming-webhook-trigger-in-atlassian-automation/
      gh_metadata(Dict[str, str]): a dictionary containing the GitHub metadata
        to attach to the request, defaults to {}.
      verbose(bool): if True body of request and response code will be printed.
    """

    headers = {}
    if jira_auth_token:
        headers[HEADER_JIRA_TOKEN] = jira_auth_token

    for record in records:
        record = {**record, **gh_metadata}
        res = requests.post(jira_url, headers=headers, json=record)
        if verbose:
            logger.info(record)
            logger.info(res)


def main(
    report_path: str,
    jira_url: str,
    jira_auth_token: str,
    gh_meta: bool,
    min_level: int,
    verbose: bool,
) -> None:
    """Main function for processing CVE's files.

    Args:
      report_path(str): path where report is stored
      jira_url(str): the url to send the request to.
      jira_auth_token(str): the auth token to use when sending requests to Jira.
        https://support.atlassian.com/cloud-automation/docs/configure-the-incoming-webhook-trigger-in-atlassian-automation/
      gh_meta(bool): if True GitHub metadata will be attached to the request.
      min_level(int): Minimum CVE level used for filtering the CVEs.
      verbose(bool): if True GitHub metadata will be attached to the request.
    """

    input_path = Path(report_path)
    gh_metadata = get_github_meta() if gh_meta else {}
    file_list = []
    if input_path.is_dir():
        # directory is supplied, retrieve list of files
        file_list = list(input_path.iterdir())
    elif input_path.is_file():
        file_list.append(input_path)
    else:
        logger.error(f"Invalid input {report_path} supplied")
        return

    if not file_list:
        logger.error(f"Failed to retrieve list of files from {report_path}")
        return

    for file in file_list:
        logger.info(f"Processing report in: {file}")
        if file.suffix == ".json":
            records = parse_json(file)
        elif file.suffix == ".sarif":
            records = parse_sarif(file)
        else:
            logger.warning(f"Unsupported file type: {file}. Skip it.")
            continue

        # Filter the records we send to Jira.
        records, excluded = filter_records(records, min_level)
        for record in excluded:
            logger.info(f"Skipping {record['name']} with priority {record['priority']}")

        send_request_with_records(records, jira_url, jira_auth_token, gh_metadata, verbose)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--report-path")
    parser.add_argument("--jira-url")
    parser.add_argument("--jira-auth-token", default="")
    parser.add_argument("--add-github-meta", action="store_true")
    parser.add_argument("--minimum-level", default=PRIORITY_LOWEST)
    parser.add_argument("--verbose", action="store_true")
    args = parser.parse_args()

    # check that the minimum level is valid.
    min_level_str = args.minimum_level.capitalize()
    if min_level_str not in priority_to_level_map:
        priorities = list(priority_to_level_map.keys())
        logger.error(f"Invalid --minimum-level '{args.minimum_level}'. Expected: {priorities}")
        sys.exit(1)

    min_level = priority_to_level_map[min_level_str]
    main(
        args.report_path,
        args.jira_url,
        args.jira_auth_token,
        args.add_github_meta,
        min_level,
        args.verbose,
    )
